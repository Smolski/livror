%\section{Correlação e regressão linear simples}


Muitas vezes há a necessidade de estudar duas ou mais variáveis ao mesmo tempo com o objetivo de predizer uma variável em função da(s) outra(s). Por exemplo, verificar se sólidos removidos de um material relaciona-se com o tempo de secagem e qual é a forma dessa relação. Outros exemplos: relação entre tempo de estudo e desempenho a uma avaliação; relação entre investimento em comunicação e vendas; entre outros.

A análise de correlação permite verificar a relação entre duas variáveis quantitativas. Os modelos de regressão permitem demonstrar a forma da relação entre duas ou mais variáveis. Estudaremos os modelos de regressão linear na qual a variáveis resposta ($Y$) é quantitativa e as variáveis preditoras ($X_i$) são quantitativas ou qualitativas.


\section{Correlação Linear}

É a técnica mais simples para estudar a relação entre duas variáveis. Os dados compõem uma única amostra de pares de valores ($x_i, y_i$), correspondendo aos valores das variáveis X e Y, respectivamente, feitas em cada elemento da amostra. Para analisar a existência de relação entre as duas variáveis, primeiramente pode-se fazer o Diagrama de Dispersão.


\section{Diagrama de Dispersão}

É um gráfico para verificar a existência de relação entre as variáveis X e Y. É composto por pontos, os quais correspondem aos pares de valores ($xi, y_i$), sendo a variável X representada no eixo horizontal e a variável Y representada no eixo vertical.

O diagrama de disperção fornece uma visualização gráfica do comportamento conjunto das duas variávei em estudo. Na Figura \ref{fig:disp1}a percebe-se uma correlação (relação) linear positiva entre as variáveis X e Y, ou seja, os valores das duas variaveis crescem conjuntamente, já na Figura \ref{fig:disp1}b percebe-se uma correlação linear negativa entre as variáveis X e Y, neste caso, os valores de uma variável crescem enquanto os valores da outra variável decrescem. A Figura \ref{fig:disp1}c informa a ausência de relação entre as duas variáveis e, a Figura \ref{fig:disp1}d mostra uma relação não linear, a qual não será objeto de estudo nesta publicação.

\begin{figure}[!htb]
\caption{Diagramas de Dispersão \label{fig:disp1}}
\centering
\includegraphics[width=1\linewidth]{correlacao1.png}
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}



\textbf{Exemplo}: Suponha que 15 alunos foram selecionados aleatoriamente na turma de Estatística, sendo registrado o tempo de estudo e nota da atividade avaliativa. O objetivo da pesquisa é verificar se existe relação entre tempo de estudo e nota.

\begin{table}[!h] \centering 
  \caption{Relação entre o tempo de estudo e a nota}
\begin{tabular}{cc}
    \hline
Tempo (h) & Nota\\
    \hline
4,0&5,5\\
6,0&7,5\\
5,5&8,0\\
5,0&7,00\\
6,8&8,1\\
6,5&8,6\\
3,5&4,7\\
4,5&7,5\\
7,0&9,5\\
8,0&9,5\\
5,4&7,8\\
6,5&8,0\\
7,7&9,1\\
7,5&9,5\\
5,8&8,00\\
    \hline
 \end{tabular}
 \legend{Fonte: Dados simulados.}
\end{table}

Sintaxe no software R:

\verb|plot(x,y)|



<<re, echo=TRUE, message=FALSE, include=TRUE, out.extra='trim={0 0.5cm 0 2cm},clip'>>=
tempo=c(4,6,5.5,5,6.8,6.5,3.5,4.5,7,8,5.4,6.5,7.7,7.5,5.8)
nota=c(5.5,7.5,8,7,8.1,8.6,4.7,7.5,9.5,9.5,7.8,8,9.1,9.5,8)
@

O diagrama de dispersão do exemplo está representado abaixo.

\begin{figure}[!h]
\caption{Diagrama de dispersão da nota em relação ao tempo de estudo dos participantes do estudo}
\centering
<<echo=TRUE, message=FALSE, fig.width=4, fig.height=2.5, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
plot(tempo,nota)
@
\label{}
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

\section{Coeficiente de Correlação Linear de Pearson}

O coeficiente de correlação linear de Pearson (Karl Pearson 1857-1936) mede o grau de relacionamento linear entre os valores pareados $x_i$ e $y_i$ em uma amostra. O coeficiente linear de Pearson é obtido da seguinte forma:

\begin{equation}
r=\frac{n\sum xy-(\sum x)(\sum y)}{\sqrt{n(\sum x^2)-(\sum x)^2} \sqrt{(\sum y^2)-(\sum y)^2}}
\end{equation}

\noindent
em que:

n = número de pares na amostra\par
x: valores da variável x\par
y: valores da variável y




O coeficiente de correlação linear (r) é uma estatística amostral, representando a magnitude da relação entre duas variáveis na amostra. O parâmetro populacional é representado por $\rho$. O coeficiente de correlação linear assume valores entre -1 e +1, inclusive. Se o valor de r está próximo de 0, conclui-se que não há correlação linear entre as variáveis X e Y. Seo valor de r está próximo de -1 ou +1, conclui-se pela existência de correlação linear significativa entre as variáveis X e Y, sendo que o sinal indica uma relação linear positiva (direta) ou negativa (inversa).


Sintaxe no software R:

\noindent
\verb|cor(x,y)|  

Obs: x e y são  numéricos.

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=2.5, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
cor(tempo,nota)
@

Lembrando que o r é uma estatística amostral, para verificar a significância aplica-se o teste estatístico. Considerando H0 = não existe correlação linear populacional entre as variáveis X e Y e H1 = existe correlação linear populacional entre as variáveis.

Sintaxe no software R:

\verb|cor.test(x,y)| 

Obs: x e y são  numéricos.

Para o exemplo:

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=2.5, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
cor.test(tempo,nota)
@


\section{Modelo de Regressão}


O estudo de regressão refere-se aos casos em que se pretende estabelecer uma relação entre uma variável Y considerada dependente (variável resposta ou desfecho) e uma ou mais variáveis $x_1, x_2,\cdots, x_k$ (variáveis explicativas ou preditoras) consideradas independentes.


O objetivo da análise de regressão é ajustar uma equação que permita explicar o comportamento da variável resposta de maneira que o valor previsto possa estar próximo do que seria observado. A forma do modelo de regressão depende da relação entre as variáveis, expressa visualmente pelo diagrama de dispersão, conforme Figura \ref{fig:disp1}.


A análise de regressão é uma técnica muito utilizada em variáveis quantitativas, como por exemplo:

\begin{itemize}
\item 	vendas em função do investimento em comunicação;

\item altura de crianças em função da idade;

\item nota obtida em função de horas de estudo;

\item 	produtividade de uma cultura em relação a quantidade de adubação.
\end{itemize}

Na Figura \ref{fig:regress} é apresentada a variação explicada e não explicada na análise por modelo regressão.

\begin{figure}[!htb]
\caption{Variação explicada e não explicada na análise de regressão}
\centering
\includegraphics[width=.9\linewidth]{regress1.png}
\label{fig:regress}
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}



Observa-se na Figura \ref{fig:regress}, uma identidade na regressão, conforme a seguinte expressão:


\begin{figure}[!h]
\caption{Identidade da Regressão}
\centering
\includegraphics[width=.8\linewidth]{regress2.png}
\label{fig:regress2}
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

Assim, a partir da expressão apresentada que o modelo de regressão será mais adequado na medida em que a proporção de ``Soma de Quadrados de Regressão'' é mais alta em relação à ``Soma de Quadrado Total'' do que a ``Soma de Quadrado do Resíduo''.


\section{Modelo de Regressão Linear Simples}



O modelo de regressão linear simples é usado quando a resposta da variável dependente se expressa de forma linear (Figura \ref{fig:regress}) e neste caso com apenas uma variável explicativa, expresso da seguinte maneira \cite{hoffmann1998}:

\begin{equation}
y_i=\beta_0+\beta_1x_i+\varepsilon _i
\end{equation}


Em que:

\begin{flushleft}

\textbf{$y_i$}: valores da variável resposta (dependente, desfecho), $i = 1,2,...,n$ observações;

\textbf{$x_i$}: valores da variável explicativa (independente, preditora), $i = 1,2,...,n$ observações;

\textbf{$\beta_0$}: coeficiente linear (intercepto). Interpretado como o valor da variável dependente quando a variável independente é igual a 0;

\textbf{$\beta_1$}: coeficiente angular (inclinação). Interpretado como acréscimo/decréscimo na variável dependente para a variação de uma unidade na variável independente;

  \textbf{$\varepsilon_i$}: erros aleatórios supostamente de uma população normal, com média 0 e variância constante $\begin{bmatrix}\varepsilon_i N(0, \sigma^2)\end{bmatrix}$.

\end{flushleft}


\section{Método dos Mínimos Quadrados}


O método dos mínimos quadrados (MMQ) é utilizado para a obtenção dos coeficientes linear e angular. Consiste em minimizar a Soma de Quadrados de Resíduos, ou seja, minimizar:

\begin{equation}
\sum (y_i-\hat y_i)^2=\sum (y_i-b_0-b_1x_i^2)
\end{equation}

As expressões para os coeficientes, que minimizam SQResíduos são obtidas pela derivadas desta soma de quadrados em relação a $b_0$ e em relação a $b_1$ e podem ser descritas por \cite{hoffmann1998}:

\begin{equation}
b_1=\frac{\sum xy-\frac{\sum x \sum y}{n}}{\sum x^2 - \frac{(\sum x)^2}{n}}
\end{equation}

\noindent
em que:


\textbf{n}: número de pares na amostra;
\textbf{x}: valores da variável x;
\textbf{y}: valores da variável y.

\noindent
e

\begin{equation}
b_0=\bar{y}-b_1\bar{x}
\end{equation}

\noindent
em que:


\textbf{$\bar{x}$}: média aritmética dos valores de x;

\textbf{$\bar{y}$}: média aritmética dos valores de y;

\textbf{$b_1$}: valor calculado do coeficiente angular.


Obtendo-se a seguinte equação de regressão linear simples estimada:

\begin{equation}
\hat{y}=b_0-b_1{x}
\end{equation}


\noindent
em que:


\textbf{$b_0$}: coeficiente linear estimado;

\textbf{$b_1$}: coeficiente angular estimado;

\textbf{$x$}: valores da variável explicativa.


Esta equação refere-se a reta de regressão, se $b_1$ é um valor positivo a reta é crescente, demonstrando uma relação positiva entre as variáveis e se $b_1$ é um o valor negativo, a reta é decrescente, demonstrando uma relação inversa entre as variáveis.


Sintaxe no software R:

\verb|regressao=lm(y~x)| 

Obs: y são valores numéricos da variável resposta e x são valores numéricos da variável preditora.

Por exemplo:

<<reg, echo=TRUE, out.extra='trim={0 0.5cm 0 2cm},clip'>>=

regressao=lm(nota~tempo)
regressao
@


\section{Análise de Variância}

A análise de variância (técnica introduzida por Fisher, na década de 20) testa o ajuste da equação como um todo, ou seja, um teste para verificar se a equação de regressão obtida é significativa ou não. No caso de regressão linear simples, a análise de variância é definida como apresentada na Tabela \ref{varian}.

As hipóteses testadas na Análise de Variância da Regressão são:

\begin{equation}
H_0:\beta_1=0 \textrm{(a regress\~ao n\~ao \'e significativa)}\\

H_1:\beta_1 \neq 0 \textrm{(a regress\~ao \'e significativa)}
\end{equation}



\begin{table}[!h] \centering 
  \caption{Análise de variância para a regressão linear simples\label{varian}}
\begin{tabular}{ccccc}
    \hline
FV & GL & SQ & QM & F\\    
    \hline
Regressão & 1 & SQRegressão  & QMRegressão& Fc\\
Desvios & n-2 & SQResíduos & QMResíduo & -\\
    \hline
Total& n-1 & SQTotal & - & -\\
    \hline
 \end{tabular}
 \legend{Fonte: Elaborado pelo(s) autor(es).}
\end{table}

\noindent
em que:

\begin{equation}
SQ \textrm{Regress\~ao} = \frac{(\sum xy - \frac{(\sum x \sum y)^2}{n})}{\sum x^2 - \frac{(\sum x)^2}{n}}
\end{equation}

\begin{equation}
SQ \textrm{Total} = \sum y^2 - \frac{(\sum y)^2}{n}
\end{equation}

\begin{flushleft}
SQResíduo = SQTotal - SQRegressão

QMRegressão = SQRegressão / GLregressão

QMResíduo = SQResíduo / GLresíduo

Fc = QMRegressão / QMResíduo
\end{flushleft}





Espera-se que o QMResíduo seja mínimo, assim o modelo de regressão estará
bem ajustado. 

A distribuição de probabilidade para a razão de duas variâncias é conhecida como a distribuição F. Se a hipótese nula for rejeitada ao nível de signicância $\alpha$, rejeita-se H0, portanto a regressão é significativa.

Sintaze no software R:

\verb|anova(regressao)| 

Obs: regressao é o nome dado ao modelo de regressão.

Por exemplo:

<<, out.extra='trim={0 0.5cm 0 2cm},clip'>>=
anova(regressao)
@


\section{Coeficiente de Determinação}

Representa o percentual de variação total que é explicada pela equação de regressão, sendo obtido da seguinte forma:

\begin{equation}
R^2 = \frac{\textrm{SQRegress\~ao}}{SQTotal}
\end{equation}

Quanto mais próximo de 1 (ou 100\%), melhor será o ajuste da equação de regressão. Também utiliza-se o coeficiente de determinação ajustado (R$^2$ ajustado), o qual considera o número de variáveis e o tamanho da amostra, sendo este o mais indicado para regressão múltipla.



Sintaxe no software R:

\verb|summary(regressao)| 

Obs: regressao é o nome dado ao modelo de regressão.

Por exemplo:

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
summary(regressao)
@

Para traçar a reta de regressão no diagrama de dispersão, utiliza-se o seguinte comando:

Sintaxe no software R:

\verb|abline(regressao)| 

Obs: regressao é o nome dado ao modelo de regressão.

Para o exemplo:

\begin{figure}[!h]
\caption{Reta de regressão ajustada da nota em relação ao tempo de estudo
dos participantes da pesquisa}
\centering
<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
plot(nota~tempo)
abline(coef(regressao))
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

O intervalo de 95\% de confiança para os coeficientes de regressão são obtidos, no software R, da seguinte forma:
	
Sintaxe no software R:

\verb|confint(regressao)| 

Obs: regressao é o nome dado ao modelo de regressão.

Para o exemplo:

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=2.5, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
confint(regressao)
@



\section{Análise dos Resíduos}


Para a validade dos intervalos de confiança e teste de hipótese torna-se necessário supor que as observações de Y sejam independentes e o termo de erro tenha distribuição aproximadamente normal com média 0 e variância constante.

O método gráfico pode ser utilizado para testar estas suposições, descrevendo que após a estimação dos parâmetros do modelo, pode-se calcular os resíduos, através da diferença entre os valores observados y e os valores preditos $\hat{y}$, associados a cada x usado na análise. Faz-se então um gráfico com os pares ($x,\varepsilon$), sendo $\varepsilon = y -\hat{y}$ \cite{barbetta1988}.

Se o modelo ajustado for apropriado para os dados, os pontos devem estar
distribuídos de forma aleatória no gráfico dos resíduos, conforme Figura \ref{fig:residuos}a. Caso a suposição não seja satisfeita, métodos alternativos podem ser utilizados como: método dos mínimos quadrados ponderados para o caso de não homocedasticidade; o método dos mínimos quadrados generalizados para o caso de erros correlacionados; e, métodos não-paramétricos para o caso de não normalidade.

Além da análise gráfica, existem testes para avaliar a homocedasticidade como o Teste de Bartlett e para avaliar a normalidade aplicam-se os testes de Shapiro Wilks ou Kolmogorov-Smirnov.



\begin{figure}[!hb]
\caption{Gráficos para análise de resíduos em regressão \label{fig:residuos}}
\centering
\includegraphics[width=1\linewidth]{residuos1.png}
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

O primeiro gráfico de resíduos que podemos elaborar é para representar os valores ajustados pela equação de regressão ajustada no eixo x e os valores dos resíduos no eixo y, conforme segue.

Sintaxe no software R:

\noindent
\verb|plot(fitted(regressao),residuals(regressao),|

\noindent
\verb|xlab="Valores ajustados",ylab="Resíduos")|

Obs: \verb|regressao| é o nome dado ao modelo de regressão, fitted define os valores ajustados no eixo x; \verb|residuals| define os valores ajustados no eixo Y; \verb|xlab| indica o nome do eixo x e \verb|ylab| indica o nome do eixo y.

\verb|abline(h=0)| (obs: adicionar uma linha constante em y=0).

Na Figura \ref{residuos} é apresentado o gráfico de resíduo, no qual os resíduos são apresentados no eixo y e os valores ajustados são apresentados no eixo x.

\begin{figure}[!h]
\caption{Gráfico dos resíduos em relação aos valores ajustados para os dados do exemplo} \label{residuos}
\centering
<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
plot(fitted(regressao), residuals(regressao),
xlab="Valores ajustados", ylab="Residuos")
abline(h=0)
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}


Outro gráfico de resíduos que é possível elaborar na análise de resíduos representa a variável preditora (x) no eixo x e o resíduos no eixo Y.
	
Sintaxe no software R:

\noindent
\verb|plot(tempo,residuals(regressao),|

\noindent
\verb|xlab="Valores independente",ylab="Resíduos")|
                                      
Obs: \verb|regressao| é o nome dado ao modelo de regressão; a variável x define os valores do eixo x e residuals define os valores ajustados no eixo Y; \verb|xlab| indica o nome do eixo x e ylab indica o nome do eixo y.

\noindent
\verb|abline(h=0)| 

Obs: adicionar uma linha constante em y=0.

Por exemplo:

\begin{figure}[!h]
\caption{Gráfico gerado pelo RStudio para análise dos resíduos com os valores da variável independente} \label{residuos2}
\centering
<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
plot(tempo, residuals(regressao), xlab = "Valores independentes",
ylab="Residuos")
abline(h=0)
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

Na Figura \ref{residuos2} é apresentado o gráfico de resíduo, em que no eixo y constam os valores dos resíduos e no eixo x constam os valores da variável independente.


Considerando os dados do exemplo, suponha que um aluno estudou 6,5 horas (x=6,5), então o valor ajustado da nota (y ) é dado por 2,2214+0,9474*6,5, resultando em 8,38. Para esse caso, o resíduo é:

Yobservado – Yestimado =8 –8,38 = -0,38

Para exibir os valores ajustados e os resíduos da equação de regressão utilizam-se os seguintes comandos:

Sintaxe no software R:

\noindent
\verb|regressao$residuals|  (exibe os resíduos do modelo regressao).

\noindent
\verb|regressao$fitted.values| (exibe os valores ajustados do modelo regressao).

Por exemplo:

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
regressao$residuals
@


Para testar a suposição que os erros aleatórios têm distribuição normal, pode-se elaborar o gráfico de probabilidade normal, conforme segue:

Sintaxe no software R:

\verb|qqnorm(residuals(regressao))|


\begin{figure}[!h]
\caption{Gráfico de probabilidade normal para verificar normalidade dos resíduos} \label{qqnorm}
\centering
<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
qqnorm(residuals(regressao))
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

Ainda, pode-se construir o gráfico com a distribuiçõa da probabilidade dos resíduos, através de um histograma, verificando assim se a cauda é simétrica ou não:

\begin{figure}[!h]
\caption{Histograma de distribuição da probabilidade para os resíduos} \label{}
\centering

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
hist(x = regressao$residuals,
      xlab = "Resíduos",
      ylab = "Densidade",
      main = "",
      col = "lightgreen",
      probability = TRUE)
 
 lines(density(regressao$residuals))
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

Também, pode-se aplicar o teste de normalidade de Shapiro Wilk para verificar a normalidade dos dados, confirmando a simetria ou não da cauda do gráfico acima. O comando utilizado é o seguinte:

\verb|shapiro.test(residuals(regressao))| 

Obs: \verb|residuals(regressão)| indica os resíduos do modelo de regressão.

Por exemplo:

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
shapiro.test(residuals(regressao))
@

\subsection{Valores outliers na regressão}

Para análise dos valores outliers nos resíduos (\emph{residuals standard} e \emph{residuals studentized}), utilizam-se os seguintes comandos:

Sintaxe no software R:

\noindent
\verb|rstudent(regressao)|

\noindent
\verb|rstandard(regressao)|

<<, out.extra='trim={0 0.5cm 0 2cm},clip'>>=
rstudent(regressao)
rstandard(regressao)
@


E o gráfico para verificar valores outliers nos resíduos:

Sintaxe no software R:

\noindent
\verb|plot(rstudent(regressao))|

\noindent
\verb|plot(rstandard(regressao))|

Os gráficos dos resíduos padronizados (standard) e studentizados (student) estão apresentados nas Figuras \ref{residpad} e \ref{residst}, respectivamente.

Para o exemplo:


\begin{figure}[!h]
\caption{Resíduos padronizados para o exemplo} \label{residpad}
\centering
<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
plot(rstandard(regressao))
abline(h=2,col="red")
abline(h=-2,col="red")
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

Aqueles valores fora do intervalo [-2,+2] são possíveis outliers. 

\begin{figure}[!h]
\caption{Resíduos studentizados para o exemplo} \label{residst}
\centering
<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
plot(rstudent(regressao)) 
abline(h=2,col="red")
abline(h=-2,col="red")
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

\subsection{Valores influentes na regressão}

Para análise dos valores influentes, utiliza-se:

Sintaxe no software R:

\noindent
\verb|dffits(regressao)|

Para esse exemplo:
<<, out.extra='trim={0 0.5cm 0 2cm},clip'>>=
dffits(regressao)
@

Aqueles valores maiores que $2*(p/n)^(1/2)$ são possíveis pontos influentes. Em que, p = número de parâmetros do modelo e n = tamanho da amostra.

Para esse exemplo:
<<, out.extra='trim={0 0.5cm 0 2cm},clip'>>=
2*(2/15)^(1/2)
@


O gráfico para detectar pontos influentes pode ser elaborado pelo comando (o gráfico está apresentado na Figura \ref{ptoinf}):



\begin{figure}[!h]
\caption{Pontos influentes para o exemplo} \label{ptoinf}
\centering
<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
plot(dffits(regressao))
abline(h=-0.73,col="red")
abline(h=0.73,col="red")
@
\legend{Fonte: Elaborado pelo(s) autor(es).}
\end{figure}

O comando \verb|plot(regressao)| elabora diferentes gráficos para o diagnóstico do modelo.

\section{Intervalo de Predição}


Após o ajuste da equação de regressão linear simples, verificada a significância da equação (p $<$ 0,05) e verificada que a equação estimada se ajusta bem aos dados pelo valor do coeficiente de determinação então podemos utilizar a para predizer valores da variável Y (resposta) a partir de valores da variável X (explicativa). Caso a regressão não seja significativa a melhor predição para a variável Y é média dos valores de $y$, ou seja, $\hat{y}$.


A predição de valores só tem sentido nos seguintes casos:

\begin{itemize}
\item regressão significativa;
\item os valores de X devem estar dentro dos limites inferior e superior dos dados amostrais;
\item as inferências referem-se somente a população de onde a amostra aleatória foi extraída;
\item as suposições sobre os resíduos devem ser satisfeitas.
\end{itemize}


Quando tem-se um equação estimada do tipo $\hat{y} = b_0 + b_1x$, $\hat{y}$ representa o valor predito da variável Y para um dado valor da variável X, ou seja, é uma predição pontual, porém esta não informa a sua precisão, a qual é contemplada no intervalo de predição (da mesma forma do intervalo de confiança, já visto em inferência estatística).

O intervalo de predição para um determinado Y é dado por:

\begin{equation}
\hat{y}\pm \varepsilon
\end{equation}

\noindent
em que:


\begin{equation}
\varepsilon = t_{(n-2;\frac{a}{2})}.S_e. \sqrt{ 1+ \frac{1}{n} +  \frac{n(x_p-\bar{x})^2}{n(\sum x^2)-(\sum x)^2} }
\end{equation}

\noindent
onde:

\begin{flushleft}
\textbf{$x_p$}: o valor dado para x

\textbf{$S_e$}: o erro padrão da estimativa, definido por:
\end{flushleft}

\begin{equation}
S_e=\sqrt\textrm{QMRes\'iduo}=\sqrt\frac{\sum(y-\hat{y})^2}{n-2}
\end{equation}

Assim, obtêm-se o intervalo de predição para um determinado Y, que também pode ser expresso da seguinte forma:

\begin{equation}
(\hat{y} - \varepsilon;\hat{y} + \varepsilon)
\end{equation}

Sintaxe no software R:

\noindent
\verb|x0=data.frame(x=valor_numérico)| 

Obs: x0 recebe o valor de x.

\noindent
\verb|predict(regressao,x0,interval="prediction")|

Obs: regressao é o nome dado ao modelo de regressão.


Para o exemplo R:

<<echo=TRUE, message=FALSE,fig.width=4, fig.height=3, fig.align='center', out.extra='trim={0 0.5cm 0 2cm},clip'>>=
x0=data.frame(tempo=5.5)
predict(regressao, x0, interval="prediction")
@


